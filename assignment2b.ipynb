{"cells":[{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.ml.feature import StringIndexer\nfrom math import log\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import lit, col\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"20ec46f0-02b6-4ae7-8cdb-bc9a24ba1a50","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.option(\"header\", \"true\") \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .csv(\"/FileStore/tables/spam.csv\") \\\n    .withColumnRenamed(\"Type\", \"label_string\") \\\n    .withColumnRenamed(\"Message\", \"sms\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bf859ef4-0188-4f09-af45-79b8db0e12c5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["regexTokenizer = RegexTokenizer(inputCol=\"sms\", outputCol=\"tokens\", pattern=\"\\\\W+\")\nregexTokenized = regexTokenizer.transform(df)\nregexTokenized = regexTokenized.withColumn('tokens',F.expr(\"array_remove(transform(tokens, x -> regexp_replace(x, '[0-9]', '')), '') as tokens\"))\n\nstopwords_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_stopwords\")\nremoved = stopwords_remover.transform(regexTokenized)\n\nindexer = StringIndexer(inputCol=\"label_string\", outputCol=\"label\")\nindexed = indexer.fit(removed).transform(removed)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cfe2c403-ddc7-41d9-b777-ad350126f745","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["train, test = indexed.randomSplit([0.7, 0.3], seed = 2018)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"12c23699-b06e-4217-9ff3-e9087b7c3be9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Training Phase\nnum_ham = train.select('label').where(train.label==0.0).count() # count of all rows training dataset: ham\nnum_spam = train.select('label').where(train.label==1.0).count() # count of all rows training dataset: spam"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"64db1491-f3f7-476c-a517-3b3151f1f3d8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["distinct_ham = train.select(F.explode('tokens_stopwords').alias('distinct_ham')).where(train.label==0.0).distinct()\ndistinct_spam = train.select(F.explode('tokens_stopwords').alias('distinct_spam')).where(train.label==1.0).distinct()\n\nunique_ham = distinct_ham.count() # count of unique words in ham training dataset \nunique_spam = distinct_spam.count() # count of unique words in spam training dataset "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae791bc2-e200-4377-91f0-0895a4c0bdc8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ham_text = train.where(train.label==0).select('tokens_stopwords','label') # all rows of training dataset: ham \nspam_text = train.where(train.label==1).select('tokens_stopwords','label') # all rows of training dataset: spam"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"db4df7e2-92dd-4d10-a432-a68e9ff05edf","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ham_prior = ham_text.count() / train.count() # prior for training dataset: ham \nspam_prior = spam_text.count() / train.count() # prior for training dataset: spam \nprint(\"ham_prior = \", ham_prior)\nprint(\"spam_prior = \", spam_prior)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f1696cee-46e9-46fc-b69c-185697b0591b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["ham_prior =  0.8675213675213675\nspam_prior =  0.13247863247863248\n"]}],"execution_count":0},{"cell_type":"code","source":["all_ham = train.select(F.explode('tokens_stopwords').alias('distinct_ham')).where(train.label==0.0).count() # count of all words in training dataset: ham\nall_spam = train.select(F.explode('tokens_stopwords').alias('distinct_spam')).where(train.label==1.0).count() # count of all words in training dataset: spam"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c8b8cb1a-e61a-411f-bb62-9a29efc0c3b5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["key_list = distinct_ham.union(distinct_spam).withColumnRenamed(\"distinct_ham\",\"all_words\") # all words in ham and spam\ntotal_type = key_list.count() # count of all words in ham and spam"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de54627c-02d6-48dc-b13f-cdb869c99e32","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ham_words_with_count = train.select(F.explode('tokens_stopwords').alias('ham_words')).where(train.label==0.0).groupBy('ham_words').count().withColumn(\"cond_prob\", lit(0.0).cast('long'))\ntotal_den_ham =  all_ham + total_type\nham_train_count = ham_words_with_count.rdd.map(lambda x: (x[0], x[1], x[1] * 1.0/ total_den_ham)).toDF([\"ham_words\",\"count\",\"cond_prob\"]) # all ham words woth conditional prob\n\nspam_words_with_count = train.select(F.explode('tokens_stopwords').alias('spam_words')).where(train.label==1.0).groupBy('spam_words').count().withColumn(\"cond_prob\", lit(0.0).cast('long'))\ntotal_den_spam = all_spam + total_type\nspam_train_count = spam_words_with_count.rdd.map(lambda x: (x[0], x[1], x[1] * 1.0 / total_den_spam)).toDF([\"spam_words\",\"count\",\"cond_prob\"]) # all spam words woth conditional prob"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a07cd557-b7af-4ee0-bdea-bbbd603f831d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Testing Phase\ntest_data = test.select('tokens_stopwords', 'label')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1b45d397-0f27-4e7b-89c8-c2140383faae","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["distinct_ham_list = distinct_ham.select('distinct_ham').rdd.flatMap(lambda x: x).collect() # convert to list\ndistinct_spam_list = distinct_spam.select('distinct_spam').rdd.flatMap(lambda x: x).collect() # convert to list"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d53ccd92-c45e-4f30-8114-0bd3f244c462","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def predict(row):\n    score1 = log(ham_prior)\n    score2 = log(spam_prior)\n    ham_not_present = [x for x in row if x not in distinct_ham_list]\n    spam_not_present = [x for x in row if x not in distinct_spam_list]\n    if len(ham_not_present) > 0:         \n        score1 += len(ham_not_present) * log(1 / total_den_ham)\n    if len(spam_not_present) > 0:\n        score2 += len(spam_not_present) * log(1 / total_den_spam)\n        \n    ham_add = ham_train_count.filter(ham_train_count.ham_words.isin(row)).withColumn('log_prob',F.log(col('cond_prob'))).select('log_prob').groupby().sum().collect()[0][0]\n    words_not_ham = ham_train_count.filter(~ham_train_count.ham_words.isin(row)).withColumn(\"log_prob\", F.log(1 - col(\"cond_prob\"))).select('log_prob').groupby().sum().collect()[0][0]\n    if (ham_add != None) and (words_not_ham != None):\n         score1 += ham_add + words_not_ham\n            \n    spam_add = spam_train_count.filter(spam_train_count.spam_words.isin(row)).withColumn('log_prob',F.log(col('cond_prob'))).select('log_prob').groupby().sum().collect()[0][0]\n    words_not_spam = spam_train_count.filter(~spam_train_count.spam_words.isin(row)).withColumn(\"log_prob\", F.log(1 - col(\"cond_prob\"))).select('log_prob').groupby().sum().collect()[0][0]\n    \n    if (spam_add != None) and (words_not_spam != None):\n        score2 += spam_add + words_not_spam\n        \n    if (score1 >= score2): \n        return 0\n    \n    else: \n        return 1"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dda168a5-316e-445b-95f3-487850caa67b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["correct = 0\ntotal_len = test_data.count()\nrows = test_data.collect()\nfor row in rows:\n    label = row['label']\n    text = row['tokens_stopwords']\n    predicted_label = predict(text)\n    if label == predicted_label:\n        correct += 1\n        \naccuracy = correct / total_len\nprint('Accuracy = ' , accuracy * 100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90e15eb1-8dcf-4d40-a215-d31a61bee8d9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Accuracy =  91.48936170212765\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"assignment2b","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":74353938389273}},"nbformat":4,"nbformat_minor":0}
